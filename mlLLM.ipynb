{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "669bc485-717c-4d11-8f55-58ee2416aa16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'INTRODUCTION TO  MACHINE LEARNING AN EARLY DRAFT OF A PROPOSED TEXTBOOK  Nils J. Nilsson Robotics Laboratory Department of Computer Science Stanford University Stanford, CA 94305 e-mail: nilsson@cs.stanford.edu November 3, 1998  Copyright c 2005 Nils J. Nilsson This material may not be copied, reproduced, or distributed without the written permission of the copyright holder.  \\x0cii  \\x0cContents 1 Preliminaries 1.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1.1.1 What is'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ''\n",
    "with open(\"./data/MLBOOK.txt\", \"r\", encoding=\"utf8\") as f:\n",
    "    data = f.read()\n",
    "f.close()\n",
    "data = data.replace('\\n',' ')\n",
    "data[:500].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a4f3bc35-b579-44d1-8264-619ea8934b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8952\n"
     ]
    }
   ],
   "source": [
    "words = list(set(data.split()))\n",
    "vocab_size = len(words)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "37f3ae0e-8dea-4068-ac3f-158dca41e64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6591, 3698, 7743, 6923]\n",
      "INTRODUCTION TO MACHINE LEARNING\n"
     ]
    }
   ],
   "source": [
    "#Create a mapping for words to integers.\n",
    "\n",
    "stoi = { word:i for i,word in enumerate(words) }\n",
    "itos = { i:word for i,word in enumerate(words) }\n",
    "encode = lambda sent: [stoi[word] for word in sent.split()]\n",
    "decode = lambda l: ' '.join(itos[i] for i in l)\n",
    "\n",
    "print(encode('INTRODUCTION TO  MACHINE LEARNING'))\n",
    "print(decode(encode('INTRODUCTION TO  MACHINE LEARNING')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1a3c9117-fb6d-4034-99ee-c553b040bbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1eee40cc-001e-4549-9771-1423497f0073",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing data tensor\n",
    "data_tensor = torch.tensor(encode(data))\n",
    "#Splitting data into train and validation data\n",
    "n = int(0.9*len(data))\n",
    "train_data = data_tensor[:n]\n",
    "val_data = data_tensor[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "00de7cfe-bc30-4ae7-b730-4e6d74cec179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'INTRODUCTION TO MACHINE LEARNING AN EARLY DRAFT OF A PROPOSED TEXTBOOK Nils J. Nilsson Robotics Laboratory Department of Computer Science Stanford University Stanford, CA 94305 e-mail: nilsson@cs.stanford.edu November 3, 1998 Copyright c'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_length = 32\n",
    "decode(train_data[:context_length].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e15194fe-8fb6-44df-80a8-3a95db17049f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3826ebed-8c52-4447-beec-9417341f8248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [6591], output: 3698\n",
      "Input: [6591, 3698], output: 7743\n",
      "Input: [6591, 3698, 7743], output: 6923\n",
      "Input: [6591, 3698, 7743, 6923], output: 355\n",
      "Input: [6591, 3698, 7743, 6923, 355], output: 418\n",
      "Input: [6591, 3698, 7743, 6923, 355, 418], output: 5451\n",
      "Input: [6591, 3698, 7743, 6923, 355, 418, 5451], output: 4793\n",
      "Input: [6591, 3698, 7743, 6923, 355, 418, 5451, 4793], output: 6816\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:context_length].tolist()\n",
    "y = train_data[1:context_length+1].tolist()\n",
    "\n",
    "for i in range(context_length):\n",
    "    context = x[:i+1]\n",
    "    target = y[i]\n",
    "    print(f'Input: {context}, output: {target}')\n",
    "    if i==7:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f810db25-4386-48ea-a1b3-712abb276482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs\n",
      "torch.Size([8, 32])\n",
      "tensor([[6054, 6661, 5846, 7647,  455, 2635, 4877, 6054,  645, 6523, 6661, 4012,\n",
      "         2346, 6325, 4843, 4254, 7667,  455, 2635, 8289,  958, 3998, 6661, 1865,\n",
      "         6523, 4012, 8713, 6661,  531, 3395, 8681, 6523],\n",
      "        [2346, 6325, 4843, 4254, 7667,  455, 2635, 8289,  958, 3998, 6661, 1865,\n",
      "         6523, 4012, 8713, 6661,  531, 3395, 8681, 6523, 4718, 2244, 8371, 4681,\n",
      "         5849, 2635, 7059, 8343, 2244, 3388, 6922,  455],\n",
      "        [3135, 4954, 2959, 3001, 5481, 5990, 6523, 5832, 5481, 3057, 4998, 8681,\n",
      "           86, 2959, 5990, 5832, 3135, 3057, 8380, 8681, 5730, 5832, 2861, 3057,\n",
      "         4998, 8681, 6842, 7059, 6367, 5481,  477, 6523],\n",
      "        [2877, 5194, 2814, 1898, 2326, 1575, 6078, 2811,  296, 2457, 6290, 2720,\n",
      "         1146, 2594, 6544,  288, 5781, 8103, 3010, 2770,  288, 6661, 8681, 6523,\n",
      "         2811, 6236, 6325, 1146, 1252, 1865, 3135,  288],\n",
      "        [3471, 6523, 7322, 5660, 4820, 8522, 4718, 1226, 1898, 4233, 7670, 6970,\n",
      "         4641, 2490, 1898, 1691, 8670, 6661, 5359, 3902, 6325,  251, 4462, 6544,\n",
      "         1146, 4478, 4939, 6523, 3824, 3135, 3902, 7127],\n",
      "        [5032, 5751, 4718,  402, 7289, 1146, 5360, 7289, 5215, 7127,   59, 1016,\n",
      "         8858, 5849, 8604,  651, 4952,  706, 7385, 4681, 7385, 4952,  706,  651,\n",
      "         4681, 3010, 8802, 5849, 8148,  774,  774,  774],\n",
      "        [4820, 8022, 2811, 5632, 6838, 5389, 1841, 3035, 3010, 1521, 8681, 6523,\n",
      "          198, 8133, 3203, 8012, 3676,  765, 5484, 2179, 1756, 8012, 7252, 8022,\n",
      "         2811, 5632, 7658, 5156, 4051, 1575, 6838, 5389],\n",
      "        [  59, 1451, 8400,  238,  600, 2647, 1575, 6838, 6661,  770, 4528, 6246,\n",
      "         1666, 3998, 4718, 2709, 2584, 6837, 3135, 7032, 2303, 2966, 6838, 7828,\n",
      "         6296, 3526,  675,  143, 6923, 2062, 3854, 3649]])\n",
      "Targets\n",
      "torch.Size([8, 32])\n",
      "tensor([[6661, 5846, 7647,  455, 2635, 4877, 6054,  645, 6523, 6661, 4012, 2346,\n",
      "         6325, 4843, 4254, 7667,  455, 2635, 8289,  958, 3998, 6661, 1865, 6523,\n",
      "         4012, 8713, 6661,  531, 3395, 8681, 6523, 4718],\n",
      "        [6325, 4843, 4254, 7667,  455, 2635, 8289,  958, 3998, 6661, 1865, 6523,\n",
      "         4012, 8713, 6661,  531, 3395, 8681, 6523, 4718, 2244, 8371, 4681, 5849,\n",
      "         2635, 7059, 8343, 2244, 3388, 6922,  455, 6661],\n",
      "        [4954, 2959, 3001, 5481, 5990, 6523, 5832, 5481, 3057, 4998, 8681,   86,\n",
      "         2959, 5990, 5832, 3135, 3057, 8380, 8681, 5730, 5832, 2861, 3057, 4998,\n",
      "         8681, 6842, 7059, 6367, 5481,  477, 6523, 1146],\n",
      "        [5194, 2814, 1898, 2326, 1575, 6078, 2811,  296, 2457, 6290, 2720, 1146,\n",
      "         2594, 6544,  288, 5781, 8103, 3010, 2770,  288, 6661, 8681, 6523, 2811,\n",
      "         6236, 6325, 1146, 1252, 1865, 3135,  288, 6661],\n",
      "        [6523, 7322, 5660, 4820, 8522, 4718, 1226, 1898, 4233, 7670, 6970, 4641,\n",
      "         2490, 1898, 1691, 8670, 6661, 5359, 3902, 6325,  251, 4462, 6544, 1146,\n",
      "         4478, 4939, 6523, 3824, 3135, 3902, 7127, 3010],\n",
      "        [5751, 4718,  402, 7289, 1146, 5360, 7289, 5215, 7127,   59, 1016, 8858,\n",
      "         5849, 8604,  651, 4952,  706, 7385, 4681, 7385, 4952,  706,  651, 4681,\n",
      "         3010, 8802, 5849, 8148,  774,  774,  774, 6922],\n",
      "        [8022, 2811, 5632, 6838, 5389, 1841, 3035, 3010, 1521, 8681, 6523,  198,\n",
      "         8133, 3203, 8012, 3676,  765, 5484, 2179, 1756, 8012, 7252, 8022, 2811,\n",
      "         5632, 7658, 5156, 4051, 1575, 6838, 5389, 1841],\n",
      "        [1451, 8400,  238,  600, 2647, 1575, 6838, 6661,  770, 4528, 6246, 1666,\n",
      "         3998, 4718, 2709, 2584, 6837, 3135, 7032, 2303, 2966, 6838, 7828, 6296,\n",
      "         3526,  675,  143, 6923, 2062, 3854, 3649, 2340]])\n"
     ]
    }
   ],
   "source": [
    "#Making batches \n",
    "\n",
    "torch.manual_seed(596)\n",
    "batch_size = 8\n",
    "context_length = 32\n",
    "\n",
    "def get_batch(split):\n",
    "    data_tensor = train_data if split=='train'  else val_data\n",
    "    ix = torch.randint(len(data_tensor)-context_length, (batch_size,))\n",
    "    x = torch.stack([data_tensor[i:i+context_length] for i in ix])\n",
    "    y = torch.stack([data_tensor[i+1:i+context_length+1] for i in ix])\n",
    "\n",
    "    return x,y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "\n",
    "print('Targets')\n",
    "print(yb.shape)\n",
    "print(yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "526a760e-b4c5-46d8-b955-520aef546d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 32 8952\n",
      "torch.Size([256, 8952])\n",
      "tensor(9.6677, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Building the very basic bigram model\n",
    "from torch.nn import functional as F\n",
    "import torch.nn as nn\n",
    "torch.manual_seed(596)\n",
    "\n",
    "class BigramModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        logits = self.token_embedding_table(idx)\n",
    "        if targets is None:\n",
    "            loss=None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            print(B, T , C) # B=batch_size, T=context_lebgth, C=vocab_size\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            # print(logits.shape, targets.shape)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for i in range(max_new_tokens):\n",
    "            logits, loss = self(idx) #B, T, C\n",
    "            # print(logits.shape)\n",
    "            #Pluck the last token embedding from each batch \n",
    "            logits = logits[-1, :] #B,C\n",
    "            #Get the softmax score for each token logits in the batch.\n",
    "            probs = F.softmax(logits, dim=-1) # B,C\n",
    "            #Next token prediction\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) #B,1\n",
    "            # print(idx.shape, idx_next.shape)\n",
    "            idx = torch.cat((idx, idx_next)) # B, T+1\n",
    "        return idx\n",
    "            \n",
    "\n",
    "m = BigramModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f9cd2979-bc46-476b-bce1-0c9473f8eb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT\n",
      "without the written permission of the copyright holder. ii Contents 1 Preliminaries 1.1 Introduction . . . . . . . .\n",
      "OUTPUT\n",
      "without the written permission of the copyright holder. ii Contents 1 Preliminaries 1.1 Introduction . . . . . . . . joining [Pomerleau, (XD less largest, studying Voronoi, Robust(u)? steers ε)?\n"
     ]
    }
   ],
   "source": [
    "inp = decode(data_tensor[45:67].tolist())\n",
    "output = decode(m.generate(data_tensor[45:67], 10).tolist())\n",
    "print('INPUT')\n",
    "print(inp)\n",
    "print('OUTPUT')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc9d9e3-b844-4ea9-911a-33423c24c84d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
